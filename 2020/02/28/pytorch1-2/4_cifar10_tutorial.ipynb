{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练一个分类器\n",
    "上一讲中已经看到如何去定义一个神经网络，计算损失值和更新网络的权重。你现在可能在想下一步。\n",
    "\n",
    "## 关于数据？\n",
    "一般情况下处理图像、文本、音频数据时，可以使用标准的Python包来加载数据到一个numpy数组中。然后把这个数组转换成torcvh.*Tensor。\n",
    "* 图像可以使用Pilolow，OpenCV\n",
    "* 音频可以使用scipy，librosa\n",
    "* 文本可以使用原始Python和Cython来加载，或者使用NLTK或SpaCyc处理\n",
    "\n",
    "特别的，对于图像任务，我们创建了一个包torchvision,它包含了处理一些基本图像数据集的方法。这些数据集包括Imagenet、CIFAR10、MNIST等。除了数据加载以外，torchvision还包含了图像转换器，torchvision.datasets和torch.utils.data.DataLoader。  \n",
    "torchvision包不仅提供了巨大的便利，也避免了代码的重复。\n",
    "在这个教程中，我们使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。CIFAR-10的图像都是 3x32x32大小的，即，3颜色通道，32x32像素。\n",
    "![图片加载失败，请稍后重试](datasets.jpg \"\")\n",
    "## 训练一个图像分类器\n",
    "依次按照下列顺序进行：\n",
    "1.使用torchvision加载和归一化CIFAR10训练集和测试机  \n",
    "2.定义一个卷积神经网络  \n",
    "3.定义损失函数  \n",
    "4.在训练集上训练网络  \n",
    "5.在测试集上测试网络  \n",
    "## 1.读取和归一化 CIFAR10\n",
    "使用torchvision可以非常容易地加载CIFAR10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision的输出是[0,1]的PILImage图像，我们把它转换为归一化范围为[-1，1]的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='',train = True,\n",
    "                                       download = False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tips：这里在CIFAR10官网已经提前下载好了数据集，和该文件放在了同一文件下，如电脑中没有CIFAR10数据集，则需将download参数置为True，root不指定参数  \n",
    "我们展示一些训练图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  ship  frog  bird\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#展示图像的函数\n",
    "\n",
    "def imshow(img):\n",
    "    img =img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "    \n",
    "# 获取随机数据\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示图象\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 显示图像标签\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.定义一个卷积神经网络\n",
    "从之前的神经网络一节复制神经网络代码，并修改为输入3通道图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.定义损失函数和优化器\n",
    "我们使用交叉熵作为损失函数，使用带动量的随机梯度下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.训练网络\n",
    "有趣的时刻开始了。我们只需在数据迭代器上循环，将数据输入给网络，并优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.058\n",
      "[1,  4000] loss: 1.772\n",
      "[1,  6000] loss: 1.639\n",
      "[1,  8000] loss: 1.547\n",
      "[1, 10000] loss: 1.485\n",
      "[1, 12000] loss: 1.442\n",
      "[2,  2000] loss: 1.371\n",
      "[2,  4000] loss: 1.357\n",
      "[2,  6000] loss: 1.310\n",
      "[2,  8000] loss: 1.315\n",
      "[2, 10000] loss: 1.281\n",
      "[2, 12000] loss: 1.260\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")      \n",
    "\n",
    "for epoch in range(2): # 多批次循环\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取输入\n",
    "        inputs, labels = data\n",
    "    \n",
    "        # 梯度置0\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # 正向传播，反向传播，优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        #打印状态信息\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 每2000批次打印一次\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.在测试集上测试网络\n",
    "我们在整个训练集上进行了两次训练，但是我们需要检查网络是否从数据集中学习到有用的东西。通过预测神经网络输出的类标签与实际情况标签进行对比来进行检测。如果预测正确，我们把该样本添加到正确预测列表。第一步，显示测试集中图片并熟悉图片内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 显示图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们看看神经网络认为以上图片是什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是10个标签的能量。 一个类别的能量越大，神经网络越认为它是这个类别。所以让我们得到最高能量的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  horse  ship   dog   cat\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果看来不错。\n",
    "\n",
    "接下来让看看网络在整个测试集上的结果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果看起来不错，至少比随机选择要好，随机选择的正确率为10%。 似乎网络学习到了一些东西。\n",
    "\n",
    "在识别哪一个类的时候好，哪一个不好呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 63 %\n",
      "Accuracy of   car : 74 %\n",
      "Accuracy of  bird : 17 %\n",
      "Accuracy of   cat : 26 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 49 %\n",
      "Accuracy of  frog : 70 %\n",
      "Accuracy of horse : 75 %\n",
      "Accuracy of  ship : 68 %\n",
      "Accuracy of truck : 55 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步？\n",
    "我们如何在GPU上运行神经网络呢？\n",
    "## 在GPU上训练\n",
    "把一个神经网络移动到GPU上训练就像把一个Tensor转换GPU上一样简单。并且这个操作会递归遍历有所模块，并将其参数和缓冲区转换为CUDA张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 确认我们的电脑支持CUDA,然后显示CUDA信息\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节的其余部分假定device是CUDA设备。\n",
    "\n",
    "然后这些方法将递归遍历所有模块并将模块的参数和缓冲区 转换成CUDA张量：\n",
    "\n",
    "net.to(device)\n",
    "记住：inputs, targets 和 images 也要转换。\n",
    "\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "为什么我们没注意到GPU的速度提升很多？那是因为网络非常的小。\n",
    "\n",
    "实践: 尝试增加你的网络的宽度（第一个nn.Conv2d的第2个参数，第二个nn.Conv2d的第一个参数，它们需要是相同的数字），看看你得到了什么样的加速。\n",
    "### 实现的目标：\n",
    "* 深入了解了Pytorch的张量库和神经网络\n",
    "* 训练了一个小网络来分类图片\n",
    "\n",
    "## 多GPU训练\n",
    "如果你想使用所有的GPU得到更大的加速， 请查看数据并行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
